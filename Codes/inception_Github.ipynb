{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# Deep learning libraries\n",
    "from tensorflow.keras.models import Model,load_model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, LeakyReLU, Activation, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.utils import class_weight \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.compat.v1 import ConfigProto,InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "session = InteractiveSession(config=config)\n",
    "#tf.keras.backend.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical\n",
    "input_path = '../proc_input/covid_data/'\n",
    "def process_data(img_dims, batch_size):\n",
    "    #Data generation objects\n",
    "    x_train, y_train = list(), list()\n",
    "    x_test, y_test = list(), list()\n",
    "    x_val, y_val = list(), list()\n",
    "    # I will be making predictions off of the test set in one batch size\n",
    "    # This is useful to be able to get the confusion matrix\n",
    "    for cond in tqdm(['/NORMAL/', '/PNEUMONIA/', '/COVID/']):\n",
    "        ipath = input_path + 'train' + cond\n",
    "        #print(ipath)\n",
    "        for img in (os.listdir(input_path + 'train' + cond)):\n",
    "            impath = input_path+'train'+cond+img\n",
    "            try:\n",
    "                imga = cv2.imread(impath) #, cv2.COLOR_BGR2GRAY)\n",
    "                imga = cv2.resize(imga, (img_dims, img_dims))\n",
    "                #imga = img_to_array(imga, data_format=None)\n",
    "                imga = np.dstack([imga])\n",
    "                if cond=='/NORMAL/':\n",
    "                    label = 0\n",
    "                elif cond=='/PNEUMONIA/':\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 2\n",
    "                x_train.append(imga)\n",
    "                y_train.append(label)\n",
    "            except:\n",
    "                print('e')\n",
    "   \n",
    "    for cond in tqdm(['/NORMAL/', '/PNEUMONIA/',\"/COVID/\"]):\n",
    "        for img in (os.listdir(input_path + 'test' + cond)):\n",
    "            impath = input_path+'test'+cond+img\n",
    "            try:\n",
    "                imga = cv2.imread(impath) #, cv2.COLOR_BGR2GRAY)\n",
    "                imga = cv2.resize(imga, (img_dims, img_dims))\n",
    "                #imga = img_to_array(imga, data_format=None)\n",
    "                imga = np.dstack([imga])\n",
    "                if cond=='/NORMAL/':\n",
    "                    label = 0\n",
    "                elif cond=='/PNEUMONIA/':\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 2\n",
    "                x_test.append(imga)\n",
    "                y_test.append(label)\n",
    "            except:\n",
    "                print('f')\n",
    "    len_xtrain = len(x_train)\n",
    "    len_xtest = len(x_test)\n",
    "   \n",
    "   \n",
    "    x_test  = np.asarray(x_test)/255.0\n",
    "    x_train = np.asarray(x_train)/255.0\n",
    "    y_train = to_categorical(y_train, 3)\n",
    "    y_test = to_categorical(y_test, 3)\n",
    "   \n",
    "    # data genarators\n",
    "    #train_datagen =ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True,\n",
    "    #train_datagen =ImageDataGenerator(zoom_range=0.3, vertical_flip=True,\n",
    "    #    height_shift_range=0.1,\n",
    "    #    width_shift_range=0.1,\n",
    "    #    shear_range=0.2)\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        horizontal_flip=True,\n",
    "        height_shift_range=0.11,\n",
    "        width_shift_range=0.11,\n",
    "        rotation_range=8,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.3,\n",
    "        #brightness_range=(0.9, 1.1),\n",
    "        fill_mode='constant')\n",
    "    #test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen=ImageDataGenerator()\n",
    "    val_datagen=ImageDataGenerator()\n",
    "    train_gen = train_datagen.flow(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size)\n",
    "    test_gen = test_datagen.flow(\n",
    "        x_test, y_test,\n",
    "        batch_size=16)\n",
    "    return train_gen, test_gen, x_test, y_test, len_xtrain, len_xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "img_dims = 150\n",
    "batch_size = 32\n",
    "\n",
    "# Getting the data\n",
    "train_gen, val_gen, x_test, y_test, len_xtrain, len_xval = process_data(img_dims, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "input_tensor = Input(shape=(img_dims, img_dims, 3))\n",
    "base_model = InceptionV3(include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "x = base_model.output\n",
    "    \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096, activation='relu',activity_regularizer=l1(0.0001))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(2048, activation='relu',activity_regularizer=l1(0.0001))(x)\n",
    "x = Dropout(0.03)(x)\n",
    "x = Dense(1024, activation='relu',activity_regularizer=l1(0.0001))(x)\n",
    "x = Dropout(0.03)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.01)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "    \n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='../outputs/inception_weights.hdf5', save_best_only=True, save_weights_only=True, monitor='val_accuracy')\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=2, mode='max',min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=15, mode='min')\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "weights = {0:.7, 1:1.53, 2:17}\n",
    "print(weights)\n",
    "hist = model.fit_generator(\n",
    "               train_gen, steps_per_epoch=len_xtrain// batch_size, \n",
    "               epochs=200, validation_data=val_gen, \n",
    "               validation_steps=len_xval// batch_size,callbacks=[checkpoint,lr_reduce],class_weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../outputs/Inception.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(hist.history[met])\n",
    "    ax[i].plot(hist.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save(\"../outputs/exeption2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.load_weights('../outputs/best_inception.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.load_weights('../outputs/Pnem1/Pnem1_model/best_chkpt.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = []\n",
    "out_test = []\n",
    "for i in range(len(preds)):\n",
    "    output1.append(list(preds[i]).index(max(preds[i])))\n",
    "for i in range(len(y_test)):\n",
    "    out_test.append(list(y_test[i]).index(max(y_test[i])))\n",
    "\n",
    "print(list(np.round(output1)).count(0)/len(output1))\n",
    "print(list(out_test).count(0)/len(out_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(out_test, output1)*100\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(out_test, output1)\n",
    "print(\"normal_sense= \", cm[0][0]/(cm[0][0]+cm[0][1]+cm[0][2]))\n",
    "print(\"pneumonia_sense= \", cm[1][1]/(cm[1][0]+cm[1][1]+cm[1][2]))\n",
    "print(\"covid_sense= \", cm[2][2]/(cm[2][0]+cm[2][1]+cm[2][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"NORMAL\",\"PNEUMONIA\",\"COVID\"]],\n",
    "                  columns = [i for i in [\"NORMAL\",\"PNEUMONIA\",\"COVID\"]])\n",
    "plt.figure(figsize = (10,7))\n",
    "x = sn.heatmap(df_cm, annot=True,fmt=\"d\", cmap = \"Blues\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
